{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7mxpI3j8eG6D7TXGU24+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AffanA2003/X-ray-Dental-Detection/blob/main/modeltrain.2\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LF7stoOJZpqD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import json  # Import the json module to parse string values into dictionaries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = 'dataset.csv'\n",
        "df = pd.read_csv(csv_path)"
      ],
      "metadata": {
        "id": "FuWBa3YXakcm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir = 'images/'\n",
        "image_paths = []\n",
        "annotations = []\n",
        "labels = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    img_filename = row['filename']\n",
        "    \n",
        "    # Parse the string values into dictionaries\n",
        "    region_shape_attributes = json.loads(row['region_shape_attributes'])\n",
        "    region_attributes = json.loads(row['region_attributes'])\n",
        "    \n",
        "    annotation = {\n",
        "        'x': region_shape_attributes['x'],\n",
        "        'y': region_shape_attributes['y'],\n",
        "        'width': region_shape_attributes['width'],\n",
        "        'height': region_shape_attributes['height']\n",
        "    }\n",
        "    status = region_attributes['status']\n",
        "    \n",
        "    img_path = os.path.join(img_dir, img_filename)\n",
        "    \n",
        "    image_paths.append(img_path)\n",
        "    annotations.append(annotation)\n",
        "    labels.append(status)\n",
        "\n",
        "annotations = np.array(annotations)\n",
        "labels = np.array(labels)\n",
        "image_paths, annotations, labels = shuffle(image_paths, annotations, labels, random_state=42)"
      ],
      "metadata": {
        "id": "vFPkl-MLaqTN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_paths, test_image_paths, train_annotations, test_annotations, train_labels, test_labels = train_test_split(\n",
        "    image_paths, annotations, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((224, 224))\n",
        "    img = np.array(img) / 255.0\n",
        "    return img\n",
        "\n",
        "train_annotations = np.array(train_annotations)\n",
        "test_annotations = np.array(test_annotations)\n",
        "train_images = np.array([load_and_preprocess_image(img_path) for img_path in train_image_paths])\n",
        "test_images = np.array([load_and_preprocess_image(img_path) for img_path in test_image_paths])"
      ],
      "metadata": {
        "id": "n1mPB3S8cOcl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "test_labels = label_encoder.transform(test_labels)"
      ],
      "metadata": {
        "id": "8mtyKo9PB2v3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=10, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "zCCU1wzIdDz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e196ceff-f932-488e-ddf2-66641105bb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/6 [===================>..........] - ETA: 1:29 - loss: 35.7505 - accuracy: 0.4922"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_images)\n",
        "test_loss = mean_squared_error(test_annotations, predictions)\n",
        "print(\"Test Loss:\", test_loss)\n"
      ],
      "metadata": {
        "id": "2ZsPadgrdSml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7NEUE1d4knMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qjllc5zd7b5-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}